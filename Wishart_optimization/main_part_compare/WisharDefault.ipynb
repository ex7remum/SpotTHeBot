{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gamma\n",
    "from sklearn.neighbors import KDTree\n",
    "from collections import defaultdict\n",
    "from scipy import spatial\n",
    "import time\n",
    "\n",
    "\n",
    "class Wishart:\n",
    "    def __init__(self, wishart_neighbors, significance_level):\n",
    "        self.wishart_neighbors = wishart_neighbors  # Number of neighbors\n",
    "        self.significance_level = significance_level  # Significance level\n",
    "\n",
    "    def fit(self, X):\n",
    "        from sklearn.neighbors import KDTree\n",
    "        start = time.time()\n",
    "        \n",
    "        cKDTree = spatial.cKDTree(X, leafsize = 40)\n",
    "        distances, neighbors = cKDTree.query(data, k = self.wishart_neighbors + 1, n_jobs = -1)\n",
    "        \n",
    "        neighbors = neighbors[:, 1:]\n",
    "        \n",
    "        distances = distances[:, -1]\n",
    "        start = time.time()\n",
    "        indexes = np.argsort(distances)\n",
    "        size, dim = X.shape\n",
    "        \n",
    "        self.object_labels = np.zeros(size, dtype = int) - 1\n",
    "\n",
    "        self.clusters = np.array([(1., 1., 0)])\n",
    "        self.clusters_to_objects = defaultdict(list)\n",
    "\n",
    "        for index in indexes:\n",
    "            neighbors_clusters =\\\n",
    "                np.concatenate([self.object_labels[neighbors[index]], self.object_labels[neighbors[index]]])\n",
    "            unique_clusters = np.unique(neighbors_clusters).astype(int)\n",
    "            unique_clusters = unique_clusters[unique_clusters != -1]\n",
    "\n",
    "            if len(unique_clusters) == 0:\n",
    "                self._create_new_cluster(index, distances[index])\n",
    "            else:\n",
    "                max_cluster = unique_clusters[-1]\n",
    "                min_cluster = unique_clusters[0]\n",
    "                if max_cluster == min_cluster:\n",
    "                    if self.clusters[max_cluster][-1] < 0.5:\n",
    "                        self._add_elem_to_exist_cluster(index, distances[index], max_cluster)\n",
    "                    else:\n",
    "                        self._add_elem_to_noise(index)\n",
    "                else:\n",
    "                    my_clusters = self.clusters[unique_clusters]\n",
    "                    flags = my_clusters[:, -1]\n",
    "                    if np.min(flags) > 0.5:\n",
    "                        self._add_elem_to_noise(index)\n",
    "                    else:\n",
    "                        significan = np.power(my_clusters[:, 0], -dim) - np.power(my_clusters[:, 1], -dim)\n",
    "                        significan *= self.wishart_neighbors\n",
    "                        significan /= size\n",
    "                        significan /= np.power(np.pi, dim / 2)\n",
    "                        significan *= gamma(dim / 2 + 1)\n",
    "                        significan_index = significan >= self.significance_level\n",
    "\n",
    "                        significan_clusters = unique_clusters[significan_index]\n",
    "                        not_significan_clusters = unique_clusters[~significan_index]\n",
    "                        significan_clusters_count = len(significan_clusters)\n",
    "                        if significan_clusters_count > 1 or min_cluster == 0:\n",
    "                            self._add_elem_to_noise(index)\n",
    "                            self.clusters[significan_clusters, -1] = 1\n",
    "                            for not_sig_cluster in not_significan_clusters:\n",
    "                                if not_sig_cluster == 0:\n",
    "                                    continue\n",
    "\n",
    "                                for bad_index in self.clusters_to_objects[int(not_sig_cluster)]:\n",
    "                                    self._add_elem_to_noise(bad_index)\n",
    "                                self.clusters_to_objects[not_sig_cluster].clear()\n",
    "                        else:\n",
    "                            for cur_cluster in unique_clusters:\n",
    "                                if cur_cluster == min_cluster:\n",
    "                                    continue\n",
    "\n",
    "                                for bad_index in self.clusters_to_objects[int(cur_cluster)]:\n",
    "                                    self._add_elem_to_exist_cluster(bad_index, distances[bad_index], min_cluster)\n",
    "                                self.clusters_to_objects[int(cur_cluster)].clear()\n",
    "\n",
    "                            self._add_elem_to_exist_cluster(index, distances[index], min_cluster)\n",
    "\n",
    "        self.object_labels = self.clean_data()\n",
    "        print(\"Clusterization took: {0} s\".format(time.time() - start))\n",
    "        return self\n",
    "\n",
    "    def clean_data(self):\n",
    "        unique = np.unique(self.object_labels)\n",
    "        index = np.argsort(unique)\n",
    "        if unique[0] != 0:\n",
    "            index += 1\n",
    "        true_cluster = {unq :  index for unq, index in zip(unique, index)}\n",
    "        result = np.zeros(len(self.object_labels), dtype = int)\n",
    "        for index, unq in enumerate(self.object_labels):\n",
    "            result[index] = true_cluster[unq]\n",
    "        return result\n",
    "\n",
    "    def _add_elem_to_noise(self, index):\n",
    "        self.object_labels[index] = 0\n",
    "        self.clusters_to_objects[0].append(index)\n",
    "\n",
    "    def _create_new_cluster(self, index, dist):\n",
    "        self.object_labels[index] = len(self.clusters)\n",
    "        self.clusters_to_objects[len(self.clusters)].append(index)\n",
    "        self.clusters = np.append(self.clusters, [(dist, dist, 0)], axis = 0)\n",
    "\n",
    "    def _add_elem_to_exist_cluster(self, index, dist, cluster_label):\n",
    "        self.object_labels[index] = cluster_label\n",
    "        self.clusters_to_objects[cluster_label].append(index)\n",
    "        self.clusters[cluster_label][0] = min(self.clusters[cluster_label][0], dist)\n",
    "        self.clusters[cluster_label][1] = max(self.clusters[cluster_label][1], dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 15)\n",
      "Clusterization took: 2.163184642791748 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Wishart at 0x14e2a08b8d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#enter file with your dattaset instead of \"data.txt\"\n",
    "data = np.array(pd.read_csv('../data.txt', sep=' ', header=None))\n",
    "print(data.shape)\n",
    "neighbours = 12\n",
    "mu = 0.2\n",
    "\n",
    "W = Wishart(neighbours, mu)\n",
    "W.fit(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
